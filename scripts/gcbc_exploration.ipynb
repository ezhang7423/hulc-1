{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "overrides = []\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "with hydra.initialize(config_path=\"../conf\"):\n",
    "    cfg = hydra.compose(config_name=\"config\", overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callbacks': {'rollout_lh': {'tasks': {'_target_': 'calvin_env.envs.tasks.Tasks', 'tasks': {'rotate_red_block_right': ['rotate_object', 'block_red', -60], 'rotate_red_block_left': ['rotate_object', 'block_red', 60], 'rotate_blue_block_right': ['rotate_object', 'block_blue', -60], 'rotate_blue_block_left': ['rotate_object', 'block_blue', 60], 'rotate_pink_block_right': ['rotate_object', 'block_pink', -60], 'rotate_pink_block_left': ['rotate_object', 'block_pink', 60], 'push_red_block_right': ['push_object', 'block_red', 0.1, 0], 'push_red_block_left': ['push_object', 'block_red', -0.1, 0], 'push_blue_block_right': ['push_object', 'block_blue', 0.1, 0], 'push_blue_block_left': ['push_object', 'block_blue', -0.1, 0], 'push_pink_block_right': ['push_object', 'block_pink', 0.1, 0], 'push_pink_block_left': ['push_object', 'block_pink', -0.1, 0], 'move_slider_left': ['move_door_rel', 'base__slide', 0.15], 'move_slider_right': ['move_door_rel', 'base__slide', -0.15], 'open_drawer': ['move_door_rel', 'base__drawer', 0.12], 'close_drawer': ['move_door_rel', 'base__drawer', -0.12], 'lift_red_block_table': ['lift_object', 'block_red', 0.05, 'table', 'base_link'], 'lift_red_block_slider': ['lift_object', 'block_red', 0.03, 'table', 'plank_link'], 'lift_red_block_drawer': ['lift_object', 'block_red', 0.05, 'table', 'drawer_link'], 'lift_blue_block_table': ['lift_object', 'block_blue', 0.05, 'table', 'base_link'], 'lift_blue_block_slider': ['lift_object', 'block_blue', 0.03, 'table', 'plank_link'], 'lift_blue_block_drawer': ['lift_object', 'block_blue', 0.05, 'table', 'drawer_link'], 'lift_pink_block_table': ['lift_object', 'block_pink', 0.05, 'table', 'base_link'], 'lift_pink_block_slider': ['lift_object', 'block_pink', 0.03, 'table', 'plank_link'], 'lift_pink_block_drawer': ['lift_object', 'block_pink', 0.05, 'table', 'drawer_link'], 'place_in_slider': ['place_object', 'table', 'plank_link'], 'place_in_drawer': ['place_object', 'table', 'drawer_link'], 'stack_block': ['stack_objects'], 'unstack_block': ['unstack_objects'], 'turn_on_lightbulb': ['toggle_light', 'lightbulb', 0, 1], 'turn_off_lightbulb': ['toggle_light', 'lightbulb', 1, 0], 'turn_on_led': ['toggle_light', 'led', 0, 1], 'turn_off_led': ['toggle_light', 'led', 1, 0], 'push_into_drawer': ['push_object_into', ['block_red', 'block_blue', 'block_pink'], 'table', 'base_link', 'table', 'drawer_link']}}, 'val_annotations': {'rotate_red_block_right': ['take the red block and rotate it to the right'], 'rotate_red_block_left': ['take the red block and rotate it to the left'], 'rotate_blue_block_right': ['take the blue block and rotate it to the right'], 'rotate_blue_block_left': ['take the blue block and rotate it to the left'], 'rotate_pink_block_right': ['take the pink block and rotate it to the right'], 'rotate_pink_block_left': ['take the pink block and rotate it to the left'], 'push_red_block_right': ['go push the red block right'], 'push_red_block_left': ['go push the red block left'], 'push_blue_block_right': ['go push the blue block right'], 'push_blue_block_left': ['go push the blue block left'], 'push_pink_block_right': ['go push the pink block right'], 'push_pink_block_left': ['go push the pink block left'], 'move_slider_left': ['push the sliding door to the left side'], 'move_slider_right': ['push the sliding door to the right side'], 'open_drawer': ['pull the handle to open the drawer'], 'close_drawer': ['push the handle to close the drawer'], 'lift_red_block_table': ['grasp and lift the red block'], 'lift_blue_block_table': ['grasp and lift the blue block'], 'lift_pink_block_table': ['grasp and lift the pink block'], 'lift_red_block_slider': ['lift the red block from the sliding cabinet'], 'lift_blue_block_slider': ['lift the blue block from the sliding cabinet'], 'lift_pink_block_slider': ['lift the pink block from the sliding cabinet'], 'lift_red_block_drawer': ['Take the red block from the drawer'], 'lift_blue_block_drawer': ['Take the blue block from the drawer'], 'lift_pink_block_drawer': ['Take the pink block from the drawer'], 'place_in_slider': ['store the grasped block in the sliding cabinet'], 'place_in_drawer': ['store the grasped block in the drawer'], 'push_into_drawer': ['slide the block that it falls into the drawer'], 'stack_block': ['stack the grasped block'], 'unstack_block': ['remove the stacked block'], 'turn_on_lightbulb': ['use the switch to turn on the light bulb'], 'turn_off_lightbulb': ['use the switch to turn off the light bulb'], 'turn_on_led': ['press the button to turn on the led light'], 'turn_off_led': ['press the button to turn off the led light']}, '_target_': 'calvin_agent.rollout.rollout_long_horizon.RolloutLongHorizon', '_recursive_': False, 'env_cfg': {'_target_': 'calvin_agent.wrappers.calvin_env_wrapper.CalvinEnvWrapper'}, 'skip_epochs': 1, 'rollout_freq': 1, 'num_videos': 16, 'num_sequences': 128, 'replan_freq': 16, 'ep_len': 360, 'empty_cache': False, 'log_video_to_file': False, 'save_dir': './videos', 'lang_folder': '${datamodule.datasets.lang_dataset.lang_folder}', 'debug': False}, 'checkpoint': {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'save_top_k': -1, 'verbose': True, 'dirpath': 'saved_models', 'filename': '{epoch}'}, 'kl_schedule': {'_target_': 'hulc.utils.kl_callbacks.KLConstantSchedule'}, 'shm_signal': {'_target_': 'calvin_agent.datasets.utils.shared_memory_utils.SignalCallback'}}, 'datamodule': {'datasets': {'vision_dataset': {'_target_': 'calvin_agent.datasets.shm_dataset.ShmDataset', 'key': 'vis', 'batch_size': 32, 'min_window_size': 10, 'max_window_size': 20, 'proprio_state': '${datamodule.proprioception_dims}', 'obs_space': '${datamodule.observation_space}', 'pad': True, 'lang_folder': 'lang_paraphrase-MiniLM-L3-v2', 'num_workers': 2}, 'lang_dataset': {'_target_': 'calvin_agent.datasets.shm_dataset.ShmDataset', 'key': 'lang', 'batch_size': 32, 'min_window_size': 10, 'max_window_size': 20, 'proprio_state': '${datamodule.proprioception_dims}', 'obs_space': '${datamodule.observation_space}', 'pad': True, 'lang_folder': 'lang_paraphrase-MiniLM-L3-v2', 'aux_lang_loss_window': 8, 'num_workers': 2}}, 'transforms': {'train': {'rgb_static': [{'_target_': 'torchvision.transforms.Resize', 'size': 200}, {'_target_': 'hulc.utils.transforms.RandomShiftsAug', 'pad': 10}, {'_target_': 'calvin_agent.utils.transforms.ScaleImageTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.5], 'std': [0.5]}], 'rgb_gripper': [{'_target_': 'torchvision.transforms.Resize', 'size': 84}, {'_target_': 'hulc.utils.transforms.RandomShiftsAug', 'pad': 4}, {'_target_': 'calvin_agent.utils.transforms.ScaleImageTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.5], 'std': [0.5]}], 'depth_static': [{'_target_': 'torchvision.transforms.Resize', 'size': 200}, {'_target_': 'calvin_agent.utils.transforms.AddDepthNoise', 'shape': [1000.0], 'rate': [1000.0]}], 'depth_gripper': [{'_target_': 'torchvision.transforms.Resize', 'size': 84}, {'_target_': 'calvin_agent.utils.transforms.AddGaussianNoise', 'mean': [0.0], 'std': [0.01]}], 'rgb_tactile': [{'_target_': 'torchvision.transforms.Resize', 'size': 70}, {'_target_': 'torchvision.transforms.RandomCrop', 'size': 64}, {'_target_': 'calvin_agent.utils.transforms.ScaleImageTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.5], 'std': [0.5]}], 'depth_tactile': [{'_target_': 'torchvision.transforms.Resize', 'size': 64}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.1], 'std': [0.2]}], 'robot_obs': [{'_target_': 'calvin_agent.utils.transforms.NormalizeVector'}], 'scene_obs': [{'_target_': 'calvin_agent.utils.transforms.NormalizeVector'}]}, 'val': {'rgb_static': [{'_target_': 'torchvision.transforms.Resize', 'size': 200}, {'_target_': 'calvin_agent.utils.transforms.ScaleImageTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.5], 'std': [0.5]}], 'rgb_gripper': [{'_target_': 'torchvision.transforms.Resize', 'size': 84}, {'_target_': 'calvin_agent.utils.transforms.ScaleImageTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.5], 'std': [0.5]}], 'depth_static': [{'_target_': 'torchvision.transforms.Resize', 'size': 200}], 'depth_gripper': [{'_target_': 'torchvision.transforms.Resize', 'size': 84}], 'rgb_tactile': [{'_target_': 'torchvision.transforms.Resize', 'size': 70}, {'_target_': 'torchvision.transforms.RandomCrop', 'size': 64}, {'_target_': 'calvin_agent.utils.transforms.ScaleImageTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.5], 'std': [0.5]}], 'depth_tactile': [{'_target_': 'torchvision.transforms.Resize', 'size': 64}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.1], 'std': [0.2]}], 'robot_obs': [{'_target_': 'calvin_agent.utils.transforms.NormalizeVector'}], 'scene_obs': [{'_target_': 'calvin_agent.utils.transforms.NormalizeVector'}]}}, 'proprioception_dims': {'n_state_obs': 8, 'keep_indices': [[0, 7], [14, 15]], 'robot_orientation_idx': [3, 6], 'normalize': True, 'normalize_robot_orientation': True}, 'observation_space': {'rgb_obs': ['rgb_static', 'rgb_gripper'], 'depth_obs': [], 'state_obs': ['robot_obs'], 'actions': ['rel_actions'], 'language': ['language']}, '_target_': 'calvin_agent.datasets.calvin_data_module.CalvinDataModule', '_recursive_': False, 'root_data_dir': '${env:DATA_GRAND_CENTRAL}/task_D_D', 'action_space': 7, 'action_max': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'action_min': [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1], 'shuffle_val': False}, 'model': {'perceptual_encoder': {'rgb_static': {'_target_': 'hulc.models.perceptual_encoders.vision_network.VisionNetwork', 'input_width': 200, 'input_height': 200, 'activation_function': 'ReLU', 'dropout_vis_fc': 0.0, 'l2_normalize_output': False, 'visual_features': 64, 'num_c': 3, 'use_sinusoid': False, 'spatial_softmax_temp': 1.0}, 'rgb_gripper': {'_target_': 'hulc.models.perceptual_encoders.vision_network_gripper.VisionNetwork', 'input_width': 84, 'input_height': 84, 'activation_function': 'ReLU', 'dropout_vis_fc': 0.0, 'l2_normalize_output': False, 'visual_features': 64, 'conv_encoder': 'nature_cnn', 'num_c': 3}, 'depth_static': {}, 'depth_gripper': {}, 'proprio': {}, 'tactile': {}, '_target_': 'hulc.models.perceptual_encoders.concat_encoders.ConcatEncoders', '_recursive_': False}, 'plan_proposal': {'_target_': 'hulc.models.plan_encoders.plan_proposal_net.PlanProposalNetwork', 'perceptual_features': '???', 'latent_goal_features': '${model.visual_goal.latent_goal_features}', 'plan_features': '???', 'activation_function': 'ReLU', 'hidden_size': 2048}, 'plan_recognition': {'_target_': 'hulc.models.plan_encoders.plan_recognition_net.PlanRecognitionTransformersNetwork', 'num_heads': 8, 'num_layers': 2, 'encoder_hidden_size': 2048, 'fc_hidden_size': 4096, 'in_features': '??', 'plan_features': '???', 'action_space': '${datamodule.action_space}', 'dropout_p': 0.1, 'encoder_normalize': False, 'positional_normalize': False, 'position_embedding': True, 'max_position_embeddings': '${datamodule.datasets.lang_dataset.max_window_size}'}, 'distribution': {'_target_': 'hulc.utils.distributions.Distribution', 'dist': 'discrete', 'category_size': 32, 'class_size': 32}, 'visual_goal': {'_target_': 'hulc.models.encoders.goal_encoders.VisualGoalEncoder', 'in_features': '???', 'hidden_size': 2048, 'latent_goal_features': 32, 'l2_normalize_goal_embeddings': False, 'activation_function': 'ReLU'}, 'language_goal': {'_target_': 'hulc.models.encoders.goal_encoders.LanguageGoalEncoder', 'in_features': 384, 'hidden_size': 2048, 'latent_goal_features': 32, 'l2_normalize_goal_embeddings': False, 'activation_function': 'ReLU', 'word_dropout_p': 0.0}, 'action_decoder': {'_target_': 'hulc.models.decoders.logistic_decoder_rnn.LogisticDecoderRNN', 'n_mixtures': 10, 'hidden_size': 2048, 'out_features': '${datamodule.action_space}', 'log_scale_min': -7.0, 'act_max_bound': '${datamodule.action_max}', 'act_min_bound': '${datamodule.action_min}', 'dataset_dir': '${datamodule.root_data_dir}', 'load_action_bounds': False, 'num_classes': 10, 'latent_goal_features': '${model.visual_goal.latent_goal_features}', 'plan_features': '???', 'perceptual_features': '???', 'gripper_alpha': 1.0, 'perceptual_emb_slice': [64, 128], 'policy_rnn_dropout_p': 0.0, 'num_layers': 2, 'rnn_model': 'rnn_decoder', 'gripper_control': True, 'discrete_gripper': True}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': '${training.lr}'}, 'lr_scheduler': {'_target_': 'transformers.get_constant_schedule'}, 'bc_z_lang_decoder': {}, 'mia_lang_discriminator': {}, 'proj_vis_lang': {'_target_': 'hulc.models.auxiliary_loss_networks.proj_vis_lang.ProjVisLang', 'im_dim': '${model.plan_recognition.fc_hidden_size}', 'lang_dim': '${model.language_goal.latent_goal_features}', 'output_dim': '${model.language_goal.latent_goal_features}', 'proj_lang': True}, 'val_instructions': {'rotate_red_block_right': ['take the red block and rotate it to the right'], 'rotate_red_block_left': ['take the red block and rotate it to the left'], 'rotate_blue_block_right': ['take the blue block and rotate it to the right'], 'rotate_blue_block_left': ['take the blue block and rotate it to the left'], 'rotate_pink_block_right': ['take the pink block and rotate it to the right'], 'rotate_pink_block_left': ['take the pink block and rotate it to the left'], 'push_red_block_right': ['go push the red block right'], 'push_red_block_left': ['go push the red block left'], 'push_blue_block_right': ['go push the blue block right'], 'push_blue_block_left': ['go push the blue block left'], 'push_pink_block_right': ['go push the pink block right'], 'push_pink_block_left': ['go push the pink block left'], 'move_slider_left': ['push the sliding door to the left side'], 'move_slider_right': ['push the sliding door to the right side'], 'open_drawer': ['pull the handle to open the drawer'], 'close_drawer': ['push the handle to close the drawer'], 'lift_red_block_table': ['grasp and lift the red block'], 'lift_blue_block_table': ['grasp and lift the blue block'], 'lift_pink_block_table': ['grasp and lift the pink block'], 'lift_red_block_slider': ['lift the red block from the sliding cabinet'], 'lift_blue_block_slider': ['lift the blue block from the sliding cabinet'], 'lift_pink_block_slider': ['lift the pink block from the sliding cabinet'], 'lift_red_block_drawer': ['Take the red block from the drawer'], 'lift_blue_block_drawer': ['Take the blue block from the drawer'], 'lift_pink_block_drawer': ['Take the pink block from the drawer'], 'place_in_slider': ['store the grasped block in the sliding cabinet'], 'place_in_drawer': ['store the grasped block in the drawer'], 'push_into_drawer': ['slide the block that it falls into the drawer'], 'stack_block': ['stack the grasped block'], 'unstack_block': ['remove the stacked block'], 'turn_on_lightbulb': ['use the switch to turn on the light bulb'], 'turn_off_lightbulb': ['use the switch to turn off the light bulb'], 'turn_on_led': ['press the button to turn on the led light'], 'turn_off_led': ['press the button to turn off the led light']}, '_target_': 'hulc.models.hulc.Hulc', '_recursive_': False, 'kl_beta': '${loss.kl_beta}', 'kl_balancing_mix': '${loss.kl_balancing_mix}', 'state_recons': False, 'state_recon_beta': '${loss.state_recon_beta}', 'use_bc_z_auxiliary_loss': False, 'bc_z_auxiliary_loss_beta': '${loss.bc_z_auxiliary_loss_beta}', 'use_mia_auxiliary_loss': False, 'mia_auxiliary_loss_beta': '${loss.mia_auxiliary_loss_beta}', 'replan_freq': 16, 'use_clip_auxiliary_loss': True, 'clip_auxiliary_loss_beta': '${loss.clip_auxiliary_loss_beta}'}, 'loss': {'kl_beta': 0.01, 'state_recon_beta': 0.5, 'kl_balancing_mix': 0.8, 'bc_z_auxiliary_loss_beta': 1.0, 'mia_auxiliary_loss_beta': 1.0, 'clip_auxiliary_loss_beta': 3.0}, 'training': {'lr': 0.0002}, 'trainer': {'devices': 1, 'accelerator': 'gpu', 'precision': 16, 'val_check_interval': 1.0, 'max_epochs': 100, 'sync_batchnorm': False}, 'logger': {'_target_': 'pytorch_lightning.loggers.WandbLogger', 'save_dir': '.', 'name': 'play_lmp', 'group': 'play_lmp', 'log_model': False, 'project': 'multi_play', 'entity': 'lang-diffusion', 'id': '???'}, 'seed': 42, 'log_dir': '../', 'slurm': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
